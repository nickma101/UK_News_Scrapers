# create political participation variable
df = df %>%
mutate(participation = (participation_1 +
participation_2 +
participation_3 +
participation_4 +
participation_5 +
participation_6 +
participation_7 +
participation_8 +
participation_9) / 9)
summary(res.aov)
paste('Mean political interest:', mean(df$political_interest))
View(df_reads)
str(df_reads)
# convert columns to numeric
df_reads = df_reads %>% dplyr::mutate_at(c('previous_scroll_rate', 'max_scroll',
'survey_time', 'age', 'gender', 'education',
'modality', 'political_interest',
'political_efficacy_1', 'political_efficacy_2',
'political_efficacy_3', 'political_efficacy_4',
'political_efficacy_5', 'political_ideology',
'last_vote', 'attention', 'transphobia_1',
'transphobia_2', 'transphobia_3', 'transphobia_4', 'transphobia_5',
'transphobia_6', 'transphobia_7', 'transphobia_8',
'minority_member', 'issue_importance',
'issue_pro_1', 'issue_con_1',
'group_pro_1', 'group_pro_2', 'group_pro_3', 'group_pro_4',
'group_con_1', 'group_con_2', 'group_con_3', 'group_con_4',
'participation_1', 'participation_2', 'participation_3',
'participation_4', 'participation_5', 'participation_6',
'participation_7', 'participation_8', 'participation_9',
'symbolic_threat_1', 'symbolic_threat_2', 'symbolic_threat_3',
'realistic_threat_1', 'realistic_threat_2', 'realistic_threat_3',
'realistic_threat_4', 'realistic_threat_5', 'realistic_threat_6',
'user_satisfaction_1', 'user_satisfaction_2',
'user_satisfaction_3',
'perceived_diversity_1', 'perceived_diversity_2',
'perceived_diversity_3',
'manipulation_check_1', 'manipulation_check_2',
'manipulation_check_3', 'manipulation_check_4'),
as.numeric)
# convert columns to numeric
df_reads = df_reads %>% dplyr::mutate_at(c('previous_scroll_rate', 'max_scroll',
'survey_time', 'age', 'gender', 'education',
'modality', 'political_interest',
'political_efficacy_1', 'political_efficacy_2',
'political_efficacy_3', 'political_efficacy_4',
'political_efficacy_5', 'political_ideology_1',
'last_vote', 'attention', 'transphobia_1',
'transphobia_2', 'transphobia_3', 'transphobia_4', 'transphobia_5',
'transphobia_6', 'transphobia_7', 'transphobia_8',
'minority_member', 'issue_importance',
'issue_pro_1', 'issue_con_1',
'group_pro_1', 'group_pro_2', 'group_pro_3', 'group_pro_4',
'group_con_1', 'group_con_2', 'group_con_3', 'group_con_4',
'participation_1', 'participation_2', 'participation_3',
'participation_4', 'participation_5', 'participation_6',
'participation_7', 'participation_8', 'participation_9',
'symbolic_threat_1', 'symbolic_threat_2', 'symbolic_threat_3',
'realistic_threat_1', 'realistic_threat_2', 'realistic_threat_3',
'realistic_threat_4', 'realistic_threat_5', 'realistic_threat_6',
'user_satisfaction_1', 'user_satisfaction_2',
'user_satisfaction_3',
'perceived_diversity_1', 'perceived_diversity_2',
'perceived_diversity_3',
'manipulation_check_1', 'manipulation_check_2',
'manipulation_check_3', 'manipulation_check_4'),
as.numeric)
# convert columns to numeric
df_reads = df_reads %>% dplyr::mutate_at(c('previous_scroll_rate', 'max_scroll',
'survey_time', 'age', 'gender', 'education',
'modality', 'political_interest',
'political_efficacy_1', 'political_efficacy_2',
'political_efficacy_3', 'political_efficacy_4',
'political_efficacy_5', 'political_Ideology_1',
'last_vote', 'attention', 'transphobia_1',
'transphobia_2', 'transphobia_3', 'transphobia_4', 'transphobia_5',
'transphobia_6', 'transphobia_7', 'transphobia_8',
'minority_member', 'issue_importance',
'issue_pro_1', 'issue_con_1',
'group_pro_1', 'group_pro_2', 'group_pro_3', 'group_pro_4',
'group_con_1', 'group_con_2', 'group_con_3', 'group_con_4',
'participation_1', 'participation_2', 'participation_3',
'participation_4', 'participation_5', 'participation_6',
'participation_7', 'participation_8', 'participation_9',
'symbolic_threat_1', 'symbolic_threat_2', 'symbolic_threat_3',
'realistic_threat_1', 'realistic_threat_2', 'realistic_threat_3',
'realistic_threat_4', 'realistic_threat_5', 'realistic_threat_6',
'user_satisfaction_1', 'user_satisfaction_2',
'user_satisfaction_3',
'perceived_diversity_1', 'perceived_diversity_2',
'perceived_diversity_3',
'manipulation_check_1', 'manipulation_check_2',
'manipulation_check_3', 'manipulation_check_4'),
as.numeric)
# remove NA's
df_reads = df_reads %>%
filter(!if_any(c('previous_scroll_rate', 'max_scroll',
'survey_time',
'age',
'gender',
'education',
'modality',
'political_interest',
'political_efficacy_1', 'political_efficacy_2',
'political_efficacy_3', 'political_efficacy_4',
'political_efficacy_5', 'political_Ideology_1',
'last_vote',
'attention',
'transphobia_1', 'transphobia_2', 'transphobia_3',
'transphobia_4', 'transphobia_5', 'transphobia_6',
'transphobia_7', 'transphobia_8',
'minority_member',
'issue_importance',
'issue_pro_1', 'issue_con_1',
'group_pro_1', 'group_pro_2', 'group_pro_3', 'group_pro_4',
'group_con_1', 'group_con_2', 'group_con_3', 'group_con_4',
'participation_1', 'participation_2', 'participation_3',
'participation_4', 'participation_5', 'participation_6',
'participation_7', 'participation_8', 'participation_9',
'symbolic_threat_1', 'symbolic_threat_2', 'symbolic_threat_3',
'realistic_threat_1', 'realistic_threat_2', 'realistic_threat_3',
'realistic_threat_4', 'realistic_threat_5', 'realistic_threat_6',
'user_satisfaction_1', 'user_satisfaction_2',
'user_satisfaction_3',
'perceived_diversity_1', 'perceived_diversity_2',
'perceived_diversity_3',
'manipulation_check_1', 'manipulation_check_2',
'manipulation_check_3', 'manipulation_check_4'), is.na))
knitr::opts_chunk$set(echo = TRUE)
library(Rmisc)
library(tidyverse)
library(ggplot2)
#q = read_csv('qualtrics.csv') %>% select(random_id, EndDate, age)
views = read.csv('views.csv') %>%
dplyr::rename(article_id_new = X_sa_instance_state,
exposure_id_new = article_id,
primary_new = exposure_id,
timestamp_views_new = primary,
user_id_new = timestamp_views)
qualtrics = read.csv("qualtrics.csv") %>%
dplyr::rename(old_user_id = user_id,
user_id = random_id,
survey_time = Duration..in.seconds.) %>%
filter(age > 16) %>%
filter(nchar(user_id) >= 10)
users = read_csv("users.csv") %>% filter(nchar(user_id) >= 10)
positions = read_csv("positions.csv")
all_reads = read_csv("reads.csv")
# check for duplicates
duplicated_reads = duplicated(all_reads$exposure_id) & duplicated(all_reads$article_id) & duplicated(all_reads$primary)
# Remove duplicated rows
reads = all_reads[!duplicated_reads, ]
all_selections = read_csv("selections.csv")
# check for duplicates
duplicated_selections = duplicated(all_selections$exposure_id) & duplicated(all_selections$article_id)
# Remove duplicated rows
selections = all_selections[!duplicated_selections, ]
all_exposures = read_csv("exposures.csv")
# check for duplicates
duplicated_exposures = duplicated(all_exposures$exposure_id)
# Remove duplicated rows
exposures = all_exposures[!duplicated_exposures, ]
# Perform a full outer join to combine selections and consumption data
news_consumption = full_join(selections, reads, by = "user_id")
# Group by user_id and find the closest previous timestamp for each row
news_consumption = news_consumption %>%
group_by(user_id, timestamp_reads) %>%
filter(timestamp_selections == max(timestamp_selections[timestamp_selections < timestamp_reads], na.rm = TRUE)) %>%
ungroup()
# Create final news consumption dataframe incl. all relevant columns
news_consumption = news_consumption %>%
mutate(readingtime = timestamp_reads - timestamp_selections) %>%
select(user_id, article_id.x, article_id.y, previous_scroll_rate,
max_scroll,position, condition,
title, read_title, timestamp_reads, timestamp_selections,
exposure_id.x, exposure_id.y,
) %>%
mutate(readingtime = timestamp_reads-timestamp_selections) %>%
dplyr::rename(aritcle_id = article_id.x,
article_id_reads = article_id.y,
exposure_id = exposure_id.x,
exposure_id_reads = exposure_id.y)
# check for duplicates
duplicated_news_consumption = duplicated(news_consumption$user_id) & duplicated(news_consumption$timestamp_selections)
# Remove duplicated rows
news_consumption = news_consumption[!duplicated_news_consumption, ]
# calculate overall usage time per user
last_exposure = exposures %>%
group_by(user_id) %>%
dplyr::summarise(latest_timestamp = max(timestamp_exposures), number_of_exposures = max(exposure_number))
users = merge(users, last_exposure, by='user_id') %>%
mutate(usage_time = latest_timestamp - timestamp_start)
# df
onlookers <- users %>%
semi_join(exposures, by = "user_id") %>%
anti_join(reads, by = "user_id") %>%
merge(qualtrics, by='user_id')
#merge app data with survey data
df_reads = merge(news_consumption, users, by = 'user_id') %>%
merge(qualtrics, by='user_id')  %>%
select(0:usage_time, survey_time, informed_consent:condition.y) %>%
filter(Code == '123546798123')
# remove NAs
df_all = left_join(exposures, df_reads, by = 'exposure_id')
# keep only one row per user
df = df_reads %>%
arrange(user_id) %>%
filter(duplicated(user_id) == FALSE)
# convert columns to numeric
df_reads = df_reads %>% dplyr::mutate_at(c('previous_scroll_rate', 'max_scroll',
'survey_time',
'age',
'gender',
'education',
'modality',
'political_interest',
'political_efficacy_1', 'political_efficacy_2',
'political_efficacy_3', 'political_efficacy_4',
'political_efficacy_5', 'political_Ideology_1',
'last_vote',
'attention',
'transphobia_1', 'transphobia_2', 'transphobia_3',
'transphobia_4', 'transphobia_5', 'transphobia_6',
'transphobia_7', 'transphobia_8',
'minority_member',
'issue_importance',
'issue_pro_1', 'issue_con_1',
'group_pro_1', 'group_pro_2', 'group_pro_3', 'group_pro_4',
'group_con_1', 'group_con_2', 'group_con_3', 'group_con_4',
'participation_1', 'participation_2', 'participation_3',
'participation_4', 'participation_5', 'participation_6',
'participation_7', 'participation_8', 'participation_9',
'symbolic_threat_1', 'symbolic_threat_2', 'symbolic_threat_3',
'realistic_threat_1', 'realistic_threat_2', 'realistic_threat_3',
'realistic_threat_4', 'realistic_threat_5', 'realistic_threat_6',
'user_satisfaction_1', 'user_satisfaction_2',
'user_satisfaction_3',
'perceived_diversity_1', 'perceived_diversity_2',
'perceived_diversity_3',
'manipulation_check_1', 'manipulation_check_2',
'manipulation_check_3', 'manipulation_check_4'),
as.numeric)
# remove NA's
df_reads %>%
filter(!if_any(c('previous_scroll_rate', 'max_scroll',
'survey_time',
'age',
'gender',
'education',
'modality',
'political_interest',
'political_efficacy_1', 'political_efficacy_2',
'political_efficacy_3', 'political_efficacy_4',
'political_efficacy_5', 'political_Ideology_1',
'last_vote',
'attention',
'transphobia_1', 'transphobia_2', 'transphobia_3',
'transphobia_4', 'transphobia_5', 'transphobia_6',
'transphobia_7', 'transphobia_8',
'minority_member',
'issue_importance',
'issue_pro_1', 'issue_con_1',
'group_pro_1', 'group_pro_2', 'group_pro_3', 'group_pro_4',
'group_con_1', 'group_con_2', 'group_con_3', 'group_con_4',
'participation_1', 'participation_2', 'participation_3',
'participation_4', 'participation_5', 'participation_6',
'participation_7', 'participation_8', 'participation_9',
'symbolic_threat_1', 'symbolic_threat_2', 'symbolic_threat_3',
'realistic_threat_1', 'realistic_threat_2', 'realistic_threat_3',
'realistic_threat_4', 'realistic_threat_5', 'realistic_threat_6',
'user_satisfaction_1', 'user_satisfaction_2',
'user_satisfaction_3',
'perceived_diversity_1', 'perceived_diversity_2',
'perceived_diversity_3',
'manipulation_check_1', 'manipulation_check_2',
'manipulation_check_3', 'manipulation_check_4'), is.na))
# remove NA's
test = df_reads %>%
filter(!if_any(c('survey_time',
'age',
'gender',
'education',
'modality',
'political_interest',
'political_efficacy_1', 'political_efficacy_2',
'political_efficacy_3', 'political_efficacy_4',
'political_efficacy_5', 'political_Ideology_1',
'last_vote',
'attention',
'transphobia_1', 'transphobia_2', 'transphobia_3',
'transphobia_4', 'transphobia_5', 'transphobia_6',
'transphobia_7', 'transphobia_8',
'minority_member',
'issue_importance',
'participation_1', 'participation_2', 'participation_3',
'participation_4', 'participation_5', 'participation_6',
'participation_7', 'participation_8', 'participation_9',
'symbolic_threat_1', 'symbolic_threat_2', 'symbolic_threat_3',
'realistic_threat_1', 'realistic_threat_2', 'realistic_threat_3',
'realistic_threat_4', 'realistic_threat_5', 'realistic_threat_6',
'user_satisfaction_1', 'user_satisfaction_2',
'user_satisfaction_3',
'perceived_diversity_1', 'perceived_diversity_2',
'perceived_diversity_3',
'manipulation_check_1', 'manipulation_check_2',
'manipulation_check_3', 'manipulation_check_4'), is.na))
# remove NA's
df_reads = df_reads %>%
filter(!if_any(c('survey_time',
'age',
'gender',
'education',
'modality',
'political_interest',
'political_efficacy_1', 'political_efficacy_2',
'political_efficacy_3', 'political_efficacy_4',
'political_efficacy_5', 'political_Ideology_1',
'last_vote',
'attention',
'transphobia_1', 'transphobia_2', 'transphobia_3',
'transphobia_4', 'transphobia_5', 'transphobia_6',
'transphobia_7', 'transphobia_8',
'minority_member',
'issue_importance',
'participation_1', 'participation_2', 'participation_3',
'participation_4', 'participation_5', 'participation_6',
'participation_7', 'participation_8', 'participation_9',
'symbolic_threat_1', 'symbolic_threat_2', 'symbolic_threat_3',
'realistic_threat_1', 'realistic_threat_2', 'realistic_threat_3',
'realistic_threat_4', 'realistic_threat_5', 'realistic_threat_6',
'user_satisfaction_1', 'user_satisfaction_2',
'user_satisfaction_3',
'perceived_diversity_1', 'perceived_diversity_2',
'perceived_diversity_3',
'manipulation_check_1', 'manipulation_check_2',
'manipulation_check_3', 'manipulation_check_4'), is.na))
aov(issue_tolerance ~ alternative_voices, data)
H1b = aov(issue_tolerance ~ alternative_voices, data)
summaru(H1b)
summary(H1b)
TukeyHSD(H1b)
H1b = aov(issue_tolerance ~ alternative_voices + issue_position, data)
H1b = aov(issue_tolerance ~ alternative_voices + age + gender + education, data)
summary(H1b)
TukeyHSD(H1b)
H1b = aov(issue_tolerance ~ alternative_voices + age + gender + education, data)
summary(H1b)
TukeyHSD(H1b)
H1b = aov(issue_tolerance ~ alternative_voices + political_interest, data)
summary(H1b)
H1b = aov(issue_tolerance ~ alternative_voices + issue_importance, data)
summary(H1b)
TukeyHSD(H1b)
summary(H1b)
View(data)
library(jsonlite)
data = fromJSON(bbc_articles2023-09-28.json)
data = fromJSON("bbc_articles2023-09-28.json")
setwd("~/development/UK_News_Scrapers/production/data")
data = fromJSON("bbc_articles2023-09-28.json")
data = fromJSON("bbc_articles2023-09-28.json")
data = fromJSON("bbc_articles2023-09-28.json")
data = fromJSON("standard_articles2023-09-28.json")
data = fromJSON("standard_articles2023-09-28.json")
data = fromJSON("independent_articles2023-09-28.json")
data = fromJSON("standard_articles2023-09-28.json")
data = fromJSON("bbc_articles2023-09-28.json")
data = fromJSON("inews_articles2023-09-28.json")
data = fromJSON("independent_articles2023-09-28.json")
data = fromJSON("independent_articles2023-09-28.json")
data = fromJSON("inewsarticles2023-09-28.json")
data = fromJSON("inews2023-09-28.json")
data = fromJSON("independent_articles2023-09-28.json")
data = fromJSON("inews2023-09-28.json")
data = fromJSON("inews2023-09-28.json")
data = fromJSON("inews2023-09-28.json")
data = fromJSON("inews2023-09-28.json")
data = fromJSON("sky_articles2023-09-28.json")
data = fromJSON("sky_articles2023-09-28.json")
data = fromJSON("inews2023-09-28.json")
data = fromJSON("inews2023-09-28.json")
data = fromJSON("sky_articles2023-09-28.json")
data = fromJSON("inews_articles2023-09-28.json")
data = fromJSON(file = "inews_articles2023-11-02.json")
source("~/development/UK_News_Scrapers/production/data/data_exploration.R")
library(tidyverse)
library(rjson)
library(data.table)
data = fromJSON(file = "bbc_articles2023-11-02.json")
list_data <- Map(as.data.frame, data)
data = fromJSON(file = "bbc_articles2023-11-02.json")
list_data <- Map(as.data.frame, data)
data = fromJSON(file = "guardian_articles2023-11-02.json")
list_data <- Map(as.data.frame, data)
df_guardian <- rbindlist(list_data)
data = fromJSON(file = "guardian_articles2023-11-02.json")
list_data <- Map(as.data.frame, data)
df_guardian <- rbindlist(list_data)
View(data)
View(list_data)
data = fromJSON(file = "guardian_articles2023-11-02.json")
list_data <- Map(as.data.frame, data)
df_guardian <- rbindlist(list_data)
data = fromJSON(file = "independent_articles2023-11-02.json")
list_data <- Map(as.data.frame, data)
df_independent <- rbindlist(list_data)
data = fromJSON(file = "guardian_articles2023-11-02.json")
list_data <- Map(as.data.frame, data)
df_guardian <- rbindlist(list_data, fill=TRUE)
View(df_guardian)
data = fromJSON(file = "independent_articles2023-11-02.json")
list_data <- Map(as.data.frame, data)
df_independent <- rbindlist(list_data, fill=TRUE)
data = fromJSON(file = "bbc_articles2023-11-02.json")
list_data <- Map(as.data.frame, data)
data = fromJSON(file = "inews_articles2023-11-02.json")
list_data <- Map(as.data.frame, data)
df_inews<- rbindlist(list_data, fill=TRUE)
data = fromJSON(file = "sky_articles2023-11-02.json")
list_data <- Map(as.data.frame, data)
df_sky <- rbindlist(list_data, fill=TRUE)
data = fromJSON(file = "standard_articles2023-11-02.json")
list_data <- Map(as.data.frame, data)
df_standard <- rbindlist(list_data, fill=TRUE))
df_standard <- rbindlist(list_data, fill=TRUE)
data = fromJSON(file = "bbc_articles2023-11-02.json")
list_data <- Map(as.data.frame, data)
data = fromJSON(file = "bbc_articles2023-11-02.json")
list_data <- Map(as.data.frame, data)
df_bbc <- rbindlist(list_data)
rbind(df_guardian, df_independent)
rbind(df_guardian, df_independent, fill=True)
rbind(df_guardian, df_independent, fill=TRUE)
df = rbind(df_guardian, df_independent, fill=TRUE)
df = rbind(df_guardian, df_independent, df_inews, df_sky, df_standard, fill=TRUE)
df %>% group_by(primaryCategory) %>% summarise(n = n())
filter(grepl('2023-11-01', datePublished)
topics = df %>%
topics = df %>%
filter(grepl('2023-11-01', datePublished)) %>%
group_by(primaryCategory) %>%
summarise(n = n())
View(topics)
topics = df %>%
filter(grepl('2023-11-01', datePublished))
topics = df %>%
filter(grepl('2023-11-01', datePublished))%>%
group_by(primaryCategory) %>%
summarise(n = n())
View(df)
data = fromJSON(file = "bbc_articles2023-11-02.json")
list_data <- Map(as.data.frame, data)
data = fromJSON(file = "bbc_articles2023-11-02.json")
list_data <- Map(as.data.frame, data)
df_bbc <- rbindlist(list_data, , fill=TRUE)
non_empty_data <- Filter(function(x) !is.null(x), data)
list_data <- Map(as.data.frame, non_empty_data)
data = fromJSON(file = "bbc_articles2023-11-02.json")
# Check if the data is a list and not empty
if (is.list(data) && length(data) > 0) {
# Filter out empty elements and standardize the structure
filtered_data <- lapply(data, function(x) {
if (is.null(x) || is.data.frame(x) && nrow(x) == 0) {
NULL
} else {
as.data.frame(x)
}
})
# Filter out NULL elements
non_empty_data <- Filter(function(x) !is.null(x), filtered_data)
# Check if there are non-empty data frames to combine
if (length(non_empty_data) > 0) {
# Combine the non-empty data frames into a single data frame
df_bbc <- rbindlist(non_empty_data)
} else {
# Handle the case where there are no non-empty data frames
print("No non-empty data frames to combine.")
}
} else {
# Handle the case where the JSON data is not in the expected format
print("JSON data is not in the expected format.")
}
df_bbc <- rbindlist(list_data,
data = fromJSON(file = "bbc_articles2023-11-02.json")
list_data <- Map(as.data.frame, data)
data = fromJSON(file = "bbc_articles2023-11-02.json")
list_data <- Map(as.data.frame, data)
df_bbc <- rbindlist(list_data, fill=TRUE)
library(jsonlite)
data = fromJSON(file = "bbc_articles2023-11-02.json")
data = jsonlite::fromJSON(file = "bbc_articles2023-11-02.json")
data = fromJSON(file "bbc_articles2023-11-02.json")
data = fromJSON(file = "bbc_articles2023-11-02.json")
detach("package:jsonlite", unload = TRUE)
data = fromJSON(file = "bbc_articles2023-11-02.json")
list_data <- Map(as.data.frame, data)
json_content <- read_file("data.json")
json_content <- read_file("bbc_articles2023-11-02.json")
json_data <- fromJSON(json_content)
df_bbc <- rbindlist(json_data, fill=TRUE)
View(df_bbc)
data = fromJSON(file = "bbc_articles2023-11-02.json")
list_data <- Map(as.data.frame, data)
?Map
data2 = fromJSON(file = "bbc_articles2023-11-02.json")
data = fromJSON(file = "guardian_articles2023-11-02.json")
View(data)
View(data2)
data = fromJSON(file = "bbc_articles2023-11-02.json")
list_data <- Map(as.data.frame, data)
